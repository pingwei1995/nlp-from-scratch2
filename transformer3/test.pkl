from datasets import *

def test(model, enc_input, start_symbol):
    # Starting Reference: http://nlp.seas.harvard.edu/2018/04/03/attention.html#greedy-decoding
    enc_outputs, enc_self_attns = model.Encoder(enc_input)
    dec_input = torch.zeros(1, tgt_len).type_as(enc_input.data)
    next_symbol = start_symbol
    for i in range(0, tgt_len):
        dec_input[0][i] = next_symbol
        print("dec_input:", dec_input)

        dec_outputs, _, _ = model.Decoder(dec_input, enc_input, enc_outputs)
        #print("dec_outputs:", dec_outputs)

        projected = model.projection(dec_outputs)
        #print("projected:", projected)

        prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]
        #print("prob:", prob)

        next_word = prob.data[i]
        #print("next_word:", next_word)

        next_symbol = next_word.item()
        #print("next_symbol:", next_symbol)

    return dec_input

enc_inputs, dec_inputs, dec_outputs = make_data()
loader = Data.DataLoader(MyDataSet(enc_inputs, dec_inputs, dec_outputs), 1, True)
enc_inputs, _, _ = next(iter(loader))
print("enc_inputs:", enc_inputs)

# 2.加载模型
model = torch.load('model.pth', weights_only=False)


#3. 预测
print("enc_inputs[0].view(1, -1):", enc_inputs[0].view(1, -1))  
predict_dec_input = test(model, enc_inputs[0].view(1, -1), start_symbol=tgt_vocab["S"])
# print("predict_dec_input:", predict_dec_input)
# print("enc_inputs[0]:", enc_inputs[0])
print("enc_inputs[0].view(1, -1):", enc_inputs[0].view(1, -1))  

predict, _, _, _ = model(enc_inputs[0].view(1, -1), predict_dec_input)   #prdict:[5,16]
print("Before max, predict:\n", predict, predict.shape)
predict = predict.data.max(1, keepdim=True)[1]
print("predict",predict)

print([src_idx2word[int(i)] for i in enc_inputs[0]], '->',
      [idx2word[n.item()] for n in predict.squeeze()])
